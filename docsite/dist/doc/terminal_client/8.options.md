# Options

Some flags are available to control the input/output options for inference tasks
and actions.

## Input mode

An inference task requires a prompt. Example `infer.yml` task:

```yaml
name: explain
description: Explain code
prompt: |-
      I have this code:

      ```
      {prompt}
      ```

      Explain what the code does in details
template: 
    name: deepseek
    system: You are an AI programmer assistant
model:
    name: deepseek-coder:6.7b
    ctx: 8192
inferParams:
    min_p: 0.05
    temperature: 0.2
```

### Command line input

By default the input is taken from a command line parameter:

```bash
lm infer "some prompt"
```

In cli mode to switch back to markdown mode after a change use this option:

```bash
? $ -oc
# Clipboard output mode is on
? $ -otxt
# Text output mode
```

### Clipboard input

To use input from the clipboard copy some code and run the command
with the `-ic` option:

```bash
lm explain -ic
```

### Promptfile input

The input can be taken from a prompt file. First declare the prompt
file path in your config and update it: `features/config.yml`:

```yml
promptfile: /home/me/lm/features/src/prompt.txt
features:
  - /home/me/lm/features/dist
plugins:
  - "@docdundee/agent"
  - "@agent-smith/feat-git"
```

You can now edit the file and use it as prompt input:


```bash
lm explain -if
```

## Output mode

### Markdown output

By default the output of a task will print to the terminal in
markdown mode, rendering a pretty print of markdown text and code

In cli mode to switch back to markdown mode after a change use this option:

```bash
lm
? $ -omd
# Markdown output mode
```

### Text output

To swith to raw text output use the `-otxt` option

### Clipboad output

To copy the output of a task into the clipoard use the `-oc` option. Note:
the input and output options can be combined. Example of a clipoard input
and output:

```bash
lm some_code_task -ic -oc
```

## Chat mode

A chat mode is available after running an inference task:

```bash
lm infer "list the planets of the solar system" -c
```

This will execute the task and then go to chat mode with the prompt and the
output of the command as a chat turn. You can then chat about the task result.

<a href="javascript:openLink('/terminal_client/plugins')">Next: Plugins</a>



