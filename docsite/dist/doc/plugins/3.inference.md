# Inference

![pub package](https://img.shields.io/npm/v/@agent-smith/feat-inference)

Basic inference feature

## Install

```bash
npm i -g @agent-smith/feat-inference
```

Add the plugin and it's dependency to your `config.yml` file and run the `conf`Â command to update the cli.

```yml
plugins:
  - "@agent-smith/feat-inference"
```

```bash
lm conf
```

## Usage

Commands:

- <kbd>infer</kbd>: run an inference query
- <kbd>q</kbd>: shortcut to run an inference query without quotes in the rerminal

## Inference

Run an inference query:

```bash
lm infer "list the planets of the solar system"
```

Default model: `qwen4b` with 16k context.

To run a query with a different model:

```bash
lm infer "list the planets of the solar system" -m mistral-small:latest --ctx 16384
```

This will run the query with `mistral-small:latest`16K context

Shortcut to run an inference query without the need of quotes: use <kbd>q</kbd>:

```bash
lm q list the planets of the solar system -m mistral-small3.2:latest
```

Default inference params for this task:

- *top_k*: 20
- *top_p*: 0.8
- *min_p*: 0
- *temperature*: 0.6

## Inference parameters

To override the default inference parameters:

```bash
lm infer "list the planets of the solar system" --temperature 0.8 --min_p 0.1
```

Fo the full list of available parameters see <a href="javascript:openLink('/libraries/lm_task/specification')">LmTask spec</a>

## Options

To visualize the tokens for an inference query use the *-t* option:

```bash
lm q list the planets of the solar system -t
```

To view the prompt template and inference params info use the *-v* option:

```bash
lm q list the planets of the solar system -v
```

To continue chatting with the model after the response use the *-c* option:

```bash
lm q list the planets of the solar system -c
```

<a href="javascript:openLink('/plugins/code/git')">Next: Git</a>