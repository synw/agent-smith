# Specification

## Fields specifications

The fields in bold are required: name, description, template and model

* **name**: The name of the task.
* **description**: A brief description of the task.
* **template**: The template for the task, which defines the format and structure of the output.
  + *system*: A brief description of the task.
  + *stop*: A list of stop words or phrases to halt predictions.
  + *assistant*: The starting text to complete after the assistant template tag.
* **model**: The AI model to be used for the task.
  + **name**: The name of the model.
  + **ctx**: The context size of the model.
  + **template**: The name of the template to use.
* **models**: Alternative models to use listed by size: xsmall, small, medium, large, xlarge, xxlarge
  + **model_size**:
    + **name**
    + **ctx**: The context size of the model.
    + **template**: The name of the template to use.
* **inferParams**: The inference parameters for the model.
  + *template*: The template to use, for the backends that support it.
  + *max_tokens*: The number of predictions to return.
  + *top_k*: Limits the result set to the top K results.
  + *top_p*: Filters results based on cumulative probability.
  + *min_p*: The minimum probability for a token to be considered, relative to the probability of the most likely token.
  + *temperature*: Adjusts randomness in sampling; higher values mean more randomness.
  + *repeat_penalty*: Adjusts penalty for repeated tokens.
  + *tfs*: Set the tail free sampling value.
  + *stop*: List of stop words or phrases to halt predictions.
  + *grammar*: The gnbf grammar to use for grammar-based sampling.
  + *image_data*: The base64 images data (for multimodal models).
  + *extra*: Extra parameters to include in the payload.
* **shots**: A list of examples or "shots" that the model can use to fine-tune its output.
    - *user*: The user's input or prompt.
        + *|-*: A separator indicating the start of the user's input.
    - *assistant*: The expected output or response.
        + *|-*: A separator indicating the start of the output.
* **variables**: An optional list of variables to include in the prompt.
    - *required*: a list a required variable names
    - *optional*: a list a optional variable names

Additional doc:

- [Inference parameters doc](https://synw.github.io/locallm/types/interfaces/InferenceParams.html)
- [Templates doc](https://synw.github.io/modprompt/interfaces/interfaces.LmTemplate.html)

## Example Yaml task

Example Yaml task definition

```yaml
name: commit_msg
description: Create a commit message from a git diff
prompt: |-
    Create a the details of the commit message. Here is the first line describing
    the purpose of the commit:

    ```
    {msg}
    ```

    Here is the git diff:

    ```
    {prompt}
    ```
    
    Avoid signing the commmit. Important: output only the commit message, no other comments.
    Think carefully before you write your commit message.

template: 
    name: llama3
    system: |- 
        You are an AI programmer assistant. Your task is to write the details of a commit message from a git diff and a 
        user provided first line describing the purpose of the commit.

        Instructions for the commit messages writing:
      
        - Use the provided first line as a base to understand the purposes of the changes
        - Remember to mention the files that were changed, and what was changed
        - Focus on what was changed and why, rather than how it was changed
        - Tone: concise and professional
        
        If there are no changes or the input is blank then return a blank string    
        This is the output format that we need:

        ```text
        [User provided first line message]
        
        - A short description of the first change 
        - A short description of the second change
        ```
    stop:
        - |-
            ```
    assistant: |-
            Here is the final commit message:
            
            ```text
model: 
    name: "llama3.1:latest"
    ctx: 8192
inferParams:
    min_p: 0.05
    temperature: 0
variables:
    required:
        - msg
```


<a href="javascript:openLink('/lm_task/use_tasks')">Next: use tasks</a>