# Vision

![pub package](https://img.shields.io/npm/v/@agent-smith/feat-vision)

Vision features

## Install

```bash
npm i -g @agent-smith/feat-vision
```

Add the plugin and it's dependency to your `config.yml` file and run the `conf` command to update the cli. Note
for Llama.cpp: use the openai compatible api with this plugin, as the native api does not support images input.

```yml
plugins:
  - "@agent-smith/feat-vision"
```

```bash
lm conf
```

## Usage

### Vision task

Default model: Qwen 4b vl with 32k context.

To run an inference query using images use the <kbd>vision</kbd> job:

```bash
lm vision imgs/img1.jpeg imgs/img2.jpeg "Compare the images"
```

Important: place the prompt argument at last position.

Example with another model:

```bash
lm vision imgs/img1.jpeg "describe the image" -m ministral3b
```

## Images to base 64 action

An command to convert images to base 64 is available to use in custom workflows:

```yaml
steps:
  - action: imgs2base64
  - task: mycustomtask
```

Usage:

```bash
lm myworkflow imgs/img1.jpeg "an optional prompt" # place the prompt at the last position
```

## Code utility

The function to convert images to base64 is available:

```js
import { img2base64 } from "@agent-smith/feat-vision";

const path = "path/to/img.jpg";
const isVerbose = true;
const base64data = await img2base64(path, isVerbose);
```


<a href="javascript:openLink('/plugins/code/git')">Next: Git</a>
